{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SGuard Suffix Attack Training\n",
                "\n",
                "This notebook runs the SGuard Suffix Attack training and saves results to Google Drive."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Mount Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Setup Environment\n",
                "Clone the repository and install dependencies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "# TODO: Replace with your actual repository URL\n",
                "!rm -rf /content/sguard_attack\n",
                "!git clone https://github.com/2CHAN0/SGuardSuffix.git sguard_attack\n",
                "\n",
                "# Install dependencies\n",
                "!pip install -r sguard_attack/requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Training\n",
                "Initialize the model and run the attack, saving checkpoints to Google Drive."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import datetime\n",
                "import torch\n",
                "\n",
                "# Add the package to path\n",
                "sys.path.append('/content')\n",
                "\n",
                "from sguard_attack.config import Config\n",
                "from sguard_attack.model_utils import load_model_and_tokenizer\n",
                "from sguard_attack.dataset import Dataset\n",
                "from sguard_attack.attack import GCGAttack\n",
                "\n",
                "# Setup Save Directory\n",
                "# Create a timestamped directory in Google Drive\n",
                "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                "save_base_dir = f\"/content/drive/MyDrive/SGuard_Training_Results/{timestamp}\"\n",
                "os.makedirs(save_base_dir, exist_ok=True)\n",
                "print(f\"Saving results to: {save_base_dir}\")\n",
                "\n",
                "# Load Model & Tokenizer\n",
                "model, tokenizer = load_model_and_tokenizer()\n",
                "\n",
                "# Load Dataset\n",
                "dataset = Dataset()\n",
                "\n",
                "# Initialize Attack\n",
                "attacker = GCGAttack(model, tokenizer)\n",
                "\n",
                "print(f\"Starting attack on {len(dataset)} prompts...\")\n",
                "\n",
                "results = []\n",
                "\n",
                "for i, malicious_prompt in enumerate(dataset):\n",
                "    print(f\"\\n[{i+1}/{len(dataset)}] Attacking prompt: {malicious_prompt}\")\n",
                "    \n",
                "    # Run attack with saving enabled\n",
                "    # save_interval=10 means it will save a checkpoint every 10 steps\n",
                "    best_suffix, best_suffix_ids, best_loss = attacker.run(\n",
                "        malicious_prompt, \n",
                "        save_dir=save_base_dir, \n",
                "        save_interval=10\n",
                "    )\n",
                "    \n",
                "    print(f\"Result for '{malicious_prompt}':\")\n",
                "    print(f\"  Best Suffix: {best_suffix}\")\n",
                "    print(f\"  Final Loss: {best_loss:.4f}\")\n",
                "    \n",
                "    # Verification (String)\n",
                "    full_input = malicious_prompt + \" \" + best_suffix\n",
                "    inputs = tokenizer(full_input, return_tensors=\"pt\").to(Config.DEVICE)\n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
                "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "        \n",
                "    print(f\"  Model Output (String): {response}\")\n",
                "\n",
                "    # Verification (Tensor)\n",
                "    prompt_ids = tokenizer(malicious_prompt, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(Config.DEVICE)\n",
                "    if best_suffix_ids.dim() == 1:\n",
                "        best_suffix_ids = best_suffix_ids.unsqueeze(0)\n",
                "    \n",
                "    full_input_ids = torch.cat([prompt_ids, best_suffix_ids], dim=1)\n",
                "    with torch.no_grad():\n",
                "        outputs_tensor = model.generate(full_input_ids, max_new_tokens=10)\n",
                "        new_tokens = outputs_tensor[0][full_input_ids.shape[1]:]\n",
                "        response_tensor = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
                "    \n",
                "    print(f\"  Model Output (Tensor): {response_tensor}\")\n",
                "    \n",
                "    results.append({\n",
                "        \"prompt\": malicious_prompt,\n",
                "        \"suffix\": best_suffix,\n",
                "        \"loss\": best_loss,\n",
                "        \"output_string\": response,\n",
                "        \"output_tensor\": response_tensor\n",
                "    })\n",
                "\n",
                "# Save Final Summary\n",
                "import json\n",
                "summary_path = os.path.join(save_base_dir, \"final_summary.json\")\n",
                "with open(summary_path, 'w') as f:\n",
                "    json.dump(results, f, indent=4)\n",
                "print(f\"\\nFinal summary saved to {summary_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
