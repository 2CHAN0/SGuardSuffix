# SGuard Suffix Attack ë¬¸ì œì  ë¶„ì„ ë° í•´ê²°ë°©ì•ˆ

## ğŸ“‹ ë°œê²¬ëœ ë¬¸ì œì 

### ğŸ”´ ë¬¸ì œ 1: Chat Template ë¯¸ì‚¬ìš© (ê°€ì¥ ì¹˜ëª…ì )

**í˜„ì¬ ì½”ë“œ (ì˜ëª»ë¨):**
```python
# attack.py, line 109
prompt_ids = self.tokenizer(malicious_prompt, return_tensors="pt", 
                           add_special_tokens=False).input_ids[0]
```

**ì˜¬ë°”ë¥¸ ë°©ì‹:**
```python
messages = [{"role": "user", "content": malicious_prompt}]
input_ids = tokenizer.apply_chat_template(
    messages, 
    add_generation_prompt=True,
    tokenize=True, 
    return_tensors='pt'
)
```

**ì™œ ë¬¸ì œì¸ê°€?**
- SGuard ëª¨ë¸ì€ chat templateì„ **ë°˜ë“œì‹œ** ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤
- ê³µì‹ ë¬¸ì„œì—ì„œ `apply_chat_template()` ì‚¬ìš©ì„ ëª…ì‹œ
- Trainingê³¼ Inferenceì—ì„œ ë‹¤ë¥¸ í˜•ì‹ì„ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì´ ë‹¤ë¥´ê²Œ ë™ì‘

**ì˜í–¥:**
- Training: ì¼ë°˜ í…ìŠ¤íŠ¸ í† í°í™”
- Inference: Chat template ì‚¬ìš© (main.pyì—ì„œ `model.generate()` í˜¸ì¶œ ì‹œ)
- â†’ ì™„ì „íˆ ë‹¤ë¥¸ ì…ë ¥ í˜•ì‹!

---

### ğŸ”´ ë¬¸ì œ 2: ì˜ëª»ëœ Target Token ì²˜ë¦¬

**í˜„ì¬ ì½”ë“œ:**
```python
# config.py
TARGET_STRING = "safe"

# attack.py, line 107
target_ids = self.tokenizer(target, return_tensors="pt", 
                           add_special_tokens=False).input_ids[0]
```

**ì˜¬ë°”ë¥¸ ë°©ì‹:**
```python
vocab = tokenizer.get_vocab()
safe_token_id = vocab['safe']      # ë‹¨ì¼ í† í° ID
unsafe_token_id = vocab['unsafe']  # ë‹¨ì¼ í† í° ID
```

**ì™œ ë¬¸ì œì¸ê°€?**
- SGuardëŠ” "safe" ë˜ëŠ” "unsafe" **ë‹¨ì¼ í† í°**ë§Œ ì¶œë ¥
- í† í°í™”í•˜ë©´ ì—¬ëŸ¬ í† í°ìœ¼ë¡œ ìª¼ê°œì§ˆ ìˆ˜ ìˆìŒ
- vocabì—ì„œ ì§ì ‘ IDë¥¼ ê°€ì ¸ì™€ì•¼ ì •í™•

---

### ğŸ”´ ë¬¸ì œ 3: ì˜ëª»ëœ Loss ê³„ì‚°

**í˜„ì¬ ì½”ë“œ:**
```python
# attack.py, line 50-53
shift_logits = logits[0, loss_slice, :].contiguous()
shift_labels = input_ids[target_slice].contiguous()
loss = F.cross_entropy(shift_logits, shift_labels)
```

**ë¬¸ì œì :**
- ì—¬ëŸ¬ í† í°ì— ëŒ€í•œ ì‹œí€€ìŠ¤ ì˜ˆì¸¡ loss ê³„ì‚°
- SGuardëŠ” **ì²« ë²ˆì§¸ ìƒì„± í† í°**ë§Œ ì¤‘ìš”

**ì˜¬ë°”ë¥¸ ë°©ì‹:**
```python
# ë§ˆì§€ë§‰ ìœ„ì¹˜ì˜ logit (ë‹¤ìŒ í† í° ì˜ˆì¸¡)
next_token_logits = logits[0, -1, :]

# safeì™€ unsafe í† í°ì˜ logitë§Œ ì¶”ì¶œ
selected_logits = torch.stack([
    next_token_logits[safe_token_id],
    next_token_logits[unsafe_token_id]
])

# í™•ë¥  ê³„ì‚°
probs = torch.softmax(selected_logits, dim=0)

# safe í† í°ì˜ í™•ë¥ ì„ ìµœëŒ€í™”
loss = -torch.log(probs[0] + 1e-10)
```

---

### ğŸ”´ ë¬¸ì œ 4: Training-Inference ë¶ˆì¼ì¹˜

**Training (attack.py):**
```python
input_ids = torch.cat([prompt_ids, suffix_ids, target_ids])
# Chat template ì—†ìŒ, ê·¸ëƒ¥ concat
```

**Inference (main.py, line 31):**
```python
full_input = malicious_prompt + " " + best_suffix  # ê³µë°± ì¶”ê°€!
inputs = tokenizer(full_input, return_tensors="pt")
# ì—¬ì „íˆ chat template ì—†ì§€ë§Œ, ê³µë°±ì´ ì¶”ê°€ë¨
```

**Inference (main.py, line 46):**
```python
full_input_ids = torch.cat([prompt_ids, best_suffix_ids], dim=1)
# ê³µë°± ì—†ìŒ
```

**ë¬¸ì œì :**
1. Trainingì—ì„œëŠ” ê³µë°± ì—†ì´ concat
2. Inferenceì—ì„œëŠ” ê³µë°± ìˆìŒ (line 31) ë˜ëŠ” ì—†ìŒ (line 46)
3. ë‘˜ ë‹¤ chat templateì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
4. í† í°í™” ê²°ê³¼ê°€ ë‹¬ë¼ì§

---

### ğŸ”´ ë¬¸ì œ 5: ì…ë ¥ êµ¬ì¡°ì˜ ê°œë…ì  ì˜¤ë¥˜

**í˜„ì¬ ì ‘ê·¼:**
```
[Prompt] + [Suffix] + [Target("safe")]
```

**ì™œ ë¬¸ì œì¸ê°€?**
- Targetì„ ì…ë ¥ì— í¬í•¨ì‹œí‚¤ëŠ” ê²ƒì€ ì¼ë°˜ LM í•™ìŠµ ë°©ì‹
- SGuardëŠ” classification ëª¨ë¸
- Targetì€ **ì¶œë ¥**ì´ì§€ ì…ë ¥ì´ ì•„ë‹˜

**ì˜¬ë°”ë¥¸ ì ‘ê·¼:**
```
Input:  [Prompt] + [Suffix] (chat template ì ìš©)
Output: "safe" ë˜ëŠ” "unsafe" (ë‹¨ì¼ í† í°)
Loss:   -log P(safe | input)
```

---

## âœ… í•´ê²° ë°©ì•ˆ

### ìˆ˜ì •ëœ íŒŒì¼ë“¤

1. **attack.py**: ì™„ì „íˆ ì¬ì„¤ê³„ëœ GCG attack
   - Chat template ì‚¬ìš©
   - ë‹¨ì¼ í† í° ë¶„ë¥˜ ì²˜ë¦¬
   - ì˜¬ë°”ë¥¸ loss ê³„ì‚°
   - Training-Inference ì¼ê´€ì„±

2. **main.py**: ê²€ì¦ ë¡œì§ ê°œì„ 
   - Chat template ì‚¬ìš©
   - Training vs Inference ë¹„êµ
   - ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´

3. **config.py**: TARGET_STRING â†’ TARGET_TOKEN

### í•µì‹¬ ë³€ê²½ì‚¬í•­

#### 1. Chat Template ì‚¬ìš©
```python
messages = [{"role": "user", "content": f"{malicious_prompt} {suffix}"}]
input_ids = tokenizer.apply_chat_template(
    messages,
    add_generation_prompt=True,
    tokenize=True,
    return_tensors='pt'
)
```

#### 2. ì˜¬ë°”ë¥¸ Token ID ì‚¬ìš©
```python
vocab = tokenizer.get_vocab()
self.safe_token_id = vocab['safe']
self.unsafe_token_id = vocab['unsafe']
```

#### 3. ì˜¬ë°”ë¥¸ Loss ê³„ì‚°
```python
next_token_logits = logits[0, -1, :]
selected_logits = torch.stack([
    next_token_logits[self.safe_token_id],
    next_token_logits[self.unsafe_token_id]
])
probs = torch.softmax(selected_logits, dim=0)
loss = -torch.log(probs[0] + 1e-10)  # Maximize P(safe)
```

#### 4. Training-Inference ì¼ê´€ì„±
- Trainingê³¼ Inference ëª¨ë‘ ë™ì¼í•œ ë°©ì‹ ì‚¬ìš©
- Chat template ì ìš©
- ê³µë°± ì²˜ë¦¬ ì¼ê´€ì„±

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

### ì´ì „ (ë¬¸ì œ ìˆëŠ” ì½”ë“œ):
```
Training Loss: 0.001  (ë‚®ìŒ)
Inference Result: "unsafe"  (ì‹¤íŒ¨)
â†’ LossëŠ” ë‚®ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì‘ë™í•˜ì§€ ì•ŠìŒ
```

### ìˆ˜ì • í›„:
```
Training Loss: 0.001
Inference Result: "safe"  (ì„±ê³µ!)
â†’ Trainingê³¼ Inferenceê°€ ì¼ì¹˜
```

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ê¸°ì¡´ ì½”ë“œ (ë¬¸ì œ ìˆìŒ):
```bash
python -m sguard_attack.main
```

### ìˆ˜ì •ëœ ì½”ë“œ:
```bash
python -m sguard_attack.main
```

---

## ğŸ” ì¶”ê°€ ë””ë²„ê¹… íŒ

ìˆ˜ì •ëœ ì½”ë“œëŠ” ë‹¤ìŒ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤:

1. **Safe/Unsafe Token IDs**: ëª¨ë¸ì˜ vocabularyì—ì„œ ê°€ì ¸ì˜¨ ì •í™•í•œ ID
2. **Training Safe Prob**: í•™ìŠµ ì¤‘ ê³„ì‚°ëœ safe í™•ë¥ 
3. **Inference Safe Prob**: ì‹¤ì œ ì¶”ë¡  ì‹œ safe í™•ë¥ 
4. **Discrepancy Warning**: ë‘ ê°’ì˜ ì°¨ì´ê°€ 0.1 ì´ìƒì´ë©´ ê²½ê³ 

ì´ë¥¼ í†µí•´ Training-Inference ì¼ê´€ì„±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“ ê²°ë¡ 

**í•µì‹¬ ë¬¸ì œ:**
- Chat template ë¯¸ì‚¬ìš©
- ì˜ëª»ëœ token ì²˜ë¦¬
- ì˜ëª»ëœ loss ê³„ì‚°
- Training-Inference ë¶ˆì¼ì¹˜

**í•´ê²°ì±…:**
- ëª¨ë“  ë‹¨ê³„ì—ì„œ chat template ì‚¬ìš©
- Vocabì—ì„œ ì§ì ‘ token ID ì¶”ì¶œ
- ë‹¨ì¼ í† í° classificationì— ë§ëŠ” loss
- ì¼ê´€ëœ ì…ë ¥ í˜•ì‹

**ê²°ê³¼:**
- Training lossì™€ inference ê²°ê³¼ì˜ ì¼ì¹˜
- ì‹¤ì œë¡œ "safe" ì¶œë ¥ì„ ìœ ë„í•  ìˆ˜ ìˆëŠ” suffix ìƒì„±
